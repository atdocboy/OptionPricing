{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Generator :: COV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from scipy.stats import skew, kurtosis, linregress\n",
    "from matplotlib import pyplot as plt\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path settings\n",
    "\n",
    "path_var = 1 \n",
    "\n",
    "if (path_var == 1):\n",
    "    filepath = '/home/docboy/Desktop/Option_Pricing/datasets/'\n",
    "\n",
    "else:\n",
    "    filepath = '/home/sharan/Desktop/Option_Pricing/datasets/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# clean = pd.read_csv(filepath + 'ttm_cleaned_BANKNIFTY_2014_2018_raw.csv')\n",
    "# clean = clean.dropna()\n",
    "# filt = pd.read_csv(filepath + 'ttm_filter_param_0.04_BANKNIFTY_2015_2018.csv')\n",
    "# ts_data = pd.read_csv(filepath + 'INDEXVALUE_BANKNIFTY_2014_2018_combined_raw.csv')\n",
    "\n",
    "\n",
    "# For NIFTY50\n",
    "\n",
    "clean = pd.read_csv(filepath + 'ttm_cleaned_NIFTY50_2014_2018_raw.csv')\n",
    "clean = clean.dropna()\n",
    "filt = pd.read_csv(filepath + 'ttm_filter_param_0.04_NIFTY50_2015_2018_new.csv')\n",
    "ts_data = pd.read_csv(filepath + 'INDEXVALUE_NIFTY50_2015_2018_combined_raw.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt['TTM']=filt['ttm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(clean)\n",
    "filt['Date'] = pd.to_datetime(filt['Date'])\n",
    "filt = filt.sort_values(by='Date')\n",
    "filt.reset_index(inplace = True, drop = True)\n",
    "clean['Date'] = pd.to_datetime(clean['Date'])\n",
    "clean['Expiry'] = pd.to_datetime(clean['Expiry'])\n",
    "clean = clean.sort_values(by='Date')\n",
    "clean.reset_index(inplace = True, drop = False)\n",
    "ts_data['Date'] = pd.to_datetime(ts_data['Date'])  \n",
    "ts_data = ts_data.sort_values(by='Date')\n",
    "ts_data.reset_index(inplace = True, drop = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121063"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(data):\n",
    "    return np.mean(data),np.std(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spreadEMA(data):\n",
    "    data['Spread']=data['Close']/data['Open']\n",
    "    return np.mean(data['Spread'])\n",
    "\n",
    "def jumpEMA(data):\n",
    "    data['Jump']=data['Open']/data['Close'].shift(1)\n",
    "    data=data.loc[1:,:]\n",
    "    return np.mean(data['Jump'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atr_data(ext):\n",
    "    '''\n",
    "    This function is defined as \n",
    "    atr =  max[abs(High - Low)_t, (High_t - Close_t-1), (Low_t - Close_t-1)]\n",
    "    '''\n",
    "    # Function Logic\n",
    "#     ext = pd.DataFrame()\n",
    "#     temp = data.loc[np.logical_and(data.loc[:, 'Strike Price'] == strike , data.loc[:, 'Expiry']) == expiry]\n",
    "#     ext = ext.append(temp, ignore_index = True)\n",
    "\n",
    "    val1 = ext.loc[:, 'High']\n",
    "    val2 = ext.loc[:, 'Low']\n",
    "    val3 = ext.loc[:, 'Close']\n",
    "\n",
    "    val = pd.DataFrame()\n",
    "    val.insert(0, \"ATR\", 0)\n",
    "    for i in range(1, len(ext)):\n",
    "        low = val2.loc[i]\n",
    "        high = val1.loc[i]\n",
    "        prev_close = val3.loc[i-1]\n",
    "        a = (high/low)\n",
    "        \n",
    "        if(high>prev_close):\n",
    "            b = (high/prev_close)\n",
    "        else:\n",
    "            b = (prev_close/high)\n",
    "            \n",
    "        if(low>prev_close):\n",
    "            c = (low/prev_close)\n",
    "        else:\n",
    "            c = (prev_close/low)            \n",
    "\n",
    "        k = max(a, b, c)\n",
    "        val.loc[i-1, \"ATR\"] = k\n",
    "        \n",
    "    return np.mean(val)[0]\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option Data Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret(data, date, OHLC ,mode='log'):\n",
    "    '''\n",
    "    This function takes in 2 primary params. The function outputs a vector of simple return data\n",
    "    corressponding to previous 20 days raw ts data.\n",
    "    The function can also output the log returns on changing the value of the mode param to 'log'.\n",
    "\n",
    "    ## Modification :: The function can also output just the raw rows if mode param is set to 'e'\n",
    "\n",
    "    # Demo func\n",
    "    ret(df, '31-Jan-2019')\n",
    "    ret(df, '31-Jan-2019', 'log')\n",
    "    ret(df, '31-Jan-2019', 'e')\n",
    "    '''\n",
    "\n",
    "    if (mode == 'log'): # Func logic if log returns is desired\n",
    "        val = pd.DataFrame()\n",
    "        temp = np.log(data[OHLC])-np.log(data[OHLC].shift(1))\n",
    "        val['LR']=temp[1:]\n",
    "\n",
    "    if (mode == 'e'): # Func logic to extract the raw data\n",
    "        k = data.index[data['Date']==date][0]\n",
    "        val = pd.DataFrame()\n",
    "        val.insert(0, \"Close\", 0)\n",
    "        val.insert(0, \"High\", 0)\n",
    "        val.insert(0, \"Low\", 0)\n",
    "        val.insert(0, \"Date\", 0)\n",
    "        val[\"Close\"] = data.loc[k-19:k, \"Close\"]\n",
    "        val['High'] = data.loc[k-19:k, \"High\"]\n",
    "        val['Low'] = data.loc[k-19:k, \"Low\"]\n",
    "        val['Open'] = data.loc[k-19:k, \"Open\"]\n",
    "        val['Date'] = data.loc[k-19:k, \"Date\"]\n",
    "    val.reset_index(inplace=True, drop=True)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(ts_data, ttm, atmDate, atmError, percentage, op_data, op_data_jump, strike,spot,opPrice, prevOp):\n",
    "    \n",
    "    oi = op_data['Open Int'].iloc[-1]\n",
    "    #     print(oi)\n",
    "\n",
    "    del_oi = op_data_jump['Change in OI'].iloc[-1]\n",
    "    #     print(del_oi)\n",
    "\n",
    "    change_oi = (del_oi/oi) *100\n",
    "\n",
    "    ts_m,ts_sd = stats(ts_data['Close'])\n",
    "\n",
    "    avg_atmError=ts_m/strike\n",
    "\n",
    "    ts_atr = atr_data(ts_data)\n",
    "\n",
    "    close_log_return = ret(ts_data, atmDate,'Close',mode = 'log')\n",
    "\n",
    "    open_log_return = ret(ts_data, atmDate,'Open',mode = 'log')\n",
    "\n",
    "    high_log_return = ret(ts_data, atmDate,'High',mode = 'log')\n",
    "\n",
    "    low_log_return = ret(ts_data, atmDate,'Low',mode = 'log')    \n",
    "\n",
    "    close_log_ret_m, close_log_ret_sd = stats(close_log_return['LR'])\n",
    "\n",
    "    open_log_ret_m, open_log_ret_sd = stats(open_log_return['LR'])\n",
    "\n",
    "    high_log_ret_m, high_log_ret_sd = stats(high_log_return['LR'])\n",
    "\n",
    "    low_log_ret_m, low_log_ret_sd = stats(low_log_return['LR'])\n",
    "\n",
    "    vcov = pd.DataFrame()\n",
    "\n",
    "    vcov['close_lr']=close_log_return['LR']\n",
    "\n",
    "    vcov['open_lr']=open_log_return['LR']\n",
    "\n",
    "    vcov['high_lr']=high_log_return['LR']\n",
    "\n",
    "    vcov['low_lr']=low_log_return['LR']\n",
    "\n",
    "    covMatrix = vcov.cov()\n",
    "\n",
    "    #     print(covMatrix)\n",
    "\n",
    "    c=[]\n",
    "\n",
    "    for i in range(4):\n",
    "        for j in range(i+1,4):\n",
    "            #             print(covMatrix.iloc[i,j])\n",
    "            val = round(covMatrix.iloc[i,j],8)\n",
    "            if(val>0):\n",
    "                c.append(math.sqrt(val))\n",
    "            else:\n",
    "                c.append(-1*math.sqrt(abs(val)))\n",
    "\n",
    "    return [atmDate] + [close_log_ret_m, close_log_ret_sd, \n",
    "    open_log_ret_m, open_log_ret_sd, high_log_ret_m, high_log_ret_sd, low_log_ret_m, \n",
    "    low_log_ret_sd] + c + [change_oi, avg_atmError,ts_atr,prevOp] + [ttm, atmError,strike,spot,opPrice,percentage]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvList=[]\n",
    "cov_list=['close_lr','open_lr','high_lr','low_lr']\n",
    "for cl1 in range(len(cov_list)):\n",
    "    for cl2 in range(cl1+1,len(cov_list)):\n",
    "        cvl=cov_list[cl1]+\"_\"+cov_list[cl2]+\"_cov\"\n",
    "        cvList.append(cvl)\n",
    "# print(cvList)\n",
    "col_name = ['date'] + ['close_mean','close_sd','open_mean','open_sd','high_mean','high_sd','low_mean','low_sd'] + cvList + ['change_oi','avg_atmError','ts_atr','prevOp'] + ['ttm', 'atmError','strike','spot','opPrice','percentage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26978"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt.reset_index(drop=True,inplace=True)\n",
    "# filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "# percentage = []\n",
    "\n",
    "feat = []\n",
    "params=[]\n",
    "for index,row in filt.iterrows():\n",
    "    ttm = row['TTM']\n",
    "    strike=row['Strike Price']\n",
    "    spot=row['Underlying Value']\n",
    "    atmDate=row['Date']\n",
    "    expDate=row['Expiry']\n",
    "    close = row['Close']\n",
    "    opPrice = close\n",
    "    opsTS = clean.loc[np.logical_and(clean['Strike Price'] == strike, clean['Expiry'] == expDate)]\n",
    "    opsTS=opsTS.drop(\"index\",1)\n",
    "    opsTS.reset_index(inplace=True, drop=True)\n",
    "#     print(atmDate)\n",
    "    ind = opsTS.index[opsTS['Date']==atmDate]#Gives Index of that day itself\n",
    "    ind=ind[0]\n",
    "    if (ind > 20):\n",
    "        window = 20\n",
    "    elif (ind < 1):\n",
    "        continue\n",
    "    else:\n",
    "        window = ind\n",
    "    \n",
    "    percentage = (close/strike)*100\n",
    "    \n",
    "    ops=opsTS.loc[ind-window:ind-1,:]\n",
    "    ops.reset_index(inplace=True, drop=True)\n",
    "    if(window==20):\n",
    "        adjWindow=19\n",
    "    else:\n",
    "        adjWindow=window\n",
    "        \n",
    "    opsJump=opsTS.loc[ind-adjWindow:ind,:]\n",
    "    opsJump.reset_index(inplace=True, drop=True)\n",
    "    ts = ret(ts_data, atmDate, '', mode = 'e')\n",
    "    \n",
    "    atmError=(spot/strike)\n",
    "    prevOp=(opsTS.loc[ind-1,'Close']/strike)\n",
    "    params.append((ts,ttm,atmDate,atmError,percentage,ops,opsJump,strike,spot,opPrice,prevOp))\n",
    "#     print(opsJump.loc[:,['Open Int','Change in OI']])\n",
    "#     count = count + 1\n",
    "#     break\n",
    "    \n",
    "pool = Pool()\n",
    "for res in pool.starmap(gen,params):    \n",
    "    feat.append(res)\n",
    "    \n",
    "pool.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results=pd.DataFrame.from_records(feat, columns=col_name)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results.to_csv(filepath + 'BANKNIFTY_feature_set_ECDF_STEP_1.csv', index = False)\n",
    "\n",
    "\n",
    "\n",
    "results.to_csv(filepath + 'NIFTY50_feature_set_COV_STEP_1.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
