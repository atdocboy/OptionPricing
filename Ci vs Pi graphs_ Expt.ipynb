{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "import datetime\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,RobustScaler\n",
    "from sklearn.utils import class_weight\n",
    "from keras import optimizers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "import joblib\n",
    "import statistics\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_var = 1\n",
    "\n",
    "if (path_var == 1):\n",
    "    filepath = '/home/docboy/Desktop/Option_Pricing/datasets/'\n",
    "    modelpath = '/home/docboy/Desktop/Option_Pricing/pickles/'\n",
    "\n",
    "\n",
    "else:\n",
    "    filepath = '/home/sharan/Desktop/OptionPricing-master/datasets/'\n",
    "    modelpath = '/home/sharan/Desktop/OptionPricing-master/pickles/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_int(lst):\n",
    "    df = pd.DataFrame(lst)\n",
    "    df = df.sort_values(by = 0).reset_index(drop=True)\n",
    "    cp1 = df[np.logical_and(df[0] >= -2,df[0] <= 2)]\n",
    "    return (len(cp1)/len(df))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2679"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lower_p_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Approach var set to :: 3\n",
      "2679\n",
      "Test accuracy: 29.8618882894516\n",
      "NEM:0.13699141470698023\n",
      "Confidence Interval:83.42665173572227\n",
      "2679\n",
      "           date  lower_p  higher_p  actual_p  LowerLim_p  UpperLim_p\n",
      "0    2017-10-03    232.8    242.50     221.2       213.4      261.90\n",
      "1    2017-10-03    118.2    128.05     120.3        98.5      147.75\n",
      "2    2017-10-03     10.2     20.40      12.2       -10.2       40.80\n",
      "3    2017-10-03     20.3     30.45      17.6         0.0       50.75\n",
      "4    2017-10-03     20.2     30.30      24.7         0.0       50.50\n",
      "...         ...      ...       ...       ...         ...         ...\n",
      "2674 2018-09-26    168.0    179.20     149.3       145.6      201.60\n",
      "2675 2018-09-26     91.2    102.60      70.8        68.4      125.40\n",
      "2676 2018-09-26     90.8    102.15      87.9        68.1      124.85\n",
      "2677 2018-09-26    222.0    233.10     203.9       199.8      255.30\n",
      "2678 2018-09-26    275.0    286.00     265.8       253.0      308.00\n",
      "\n",
      "[2679 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "nfty = filepath + 'NIFTY50_feature_set_COV_complete.csv'\n",
    "nfty_ecdf = filepath + 'NIFTY50_feature_set_ECDF_complete.csv'\n",
    "\n",
    "nfty_19= filepath + 'NIFTY50_2019_feature_set_COV_complete.csv'\n",
    "nfty_ecdf_19= filepath + 'NIFTY50_2019_feature_set_ECDF_complete.csv'\n",
    "\n",
    "bnfty = filepath + 'BANKNIFTY_feature_set_COV_complete.csv'\n",
    "bnfty_ecdf = filepath + 'BANKNIFTY_feature_set_ECDF_complete.csv'\n",
    "\n",
    "\n",
    "for approach in range(3, 4):\n",
    "\n",
    "    if (approach == 1):\n",
    "        feats = pd.read_csv(nfty_ecdf)\n",
    "        print ('\\n\\nApproach var set to ECDF')\n",
    "\n",
    "\n",
    "        dropNames = ['date','percentage','strike','spot','opPrice']\n",
    "\n",
    "    else:\n",
    "        feats = pd.read_csv(nfty)\n",
    "        print ('\\n\\nApproach var set to :: '+ str(approach))\n",
    "\n",
    "\n",
    "        if (approach == 2):\n",
    "            dropNames= ['date','percentage','strike','spot','opPrice','change_oi',\n",
    "                            'ts_atr','prevOp','avg_atmError']\n",
    "\n",
    "        else:\n",
    "            dropNames= ['date', 'percentage','strike','spot','opPrice','ts_atr','change_oi']\n",
    "\n",
    "        ###################\n",
    "        \n",
    "    if (approach == 1):\n",
    "        dev = 100\n",
    "    else:\n",
    "        dev = 1\n",
    "\n",
    "        \n",
    "    feats['date'] = pd.to_datetime(feats['date'])\n",
    "    feats = feats[(feats['date']>=datetime.datetime(2017, 10, 1))]\n",
    "    feats = feats.reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    X=feats.iloc[:,:-1]\n",
    "    Y=feats.loc[:,'Target']\n",
    "    X = X.drop(dropNames, axis = 1)    \n",
    "\n",
    "    # Load the scalar file\n",
    "    scaler = joblib.load(modelpath + 'Combined_DL_SCALER_NIFTY_0.02_Expt' + str(approach) + '.model')\n",
    "\n",
    "    # Start the scaling process\n",
    "\n",
    "    featNames = list(X)  \n",
    "    X = scaler.transform(X)\n",
    "    X = pd.DataFrame(X, columns = featNames)\n",
    "\n",
    "\n",
    "    onehot = joblib.load(modelpath + 'Combined_DL_ONEHOT_NIFTY_0.02_Expt' + str(approach) + '.model')\n",
    "\n",
    "    Y = Y.values\n",
    "    Y = Y.reshape(len(Y), 1)\n",
    "    Y = onehot.transform(Y)\n",
    "\n",
    "    # Split the train and test sets without random optimization\n",
    "    \n",
    "    \n",
    "    X_test = X.iloc[:, :]\n",
    "    Y_test = Y[:] \n",
    "    print(len(Y_test))\n",
    "\n",
    "    # Saving the model\n",
    "    model = joblib.load(modelpath + 'Combined_DL_NIFTY_0.02_Expt' + str(approach) + '.model')\n",
    "\n",
    "    score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "    print('Test accuracy:', score[1]*100)\n",
    "\n",
    "    Y_pred=model.predict(X_test)\n",
    "    Y_pred=np.argmax(Y_pred,axis=1)\n",
    "\n",
    "    OGY_test=onehot.inverse_transform(Y_test)\n",
    "    # OGY_test=sum(OGY_test, [])\n",
    "    OGY_test=OGY_test.ravel()\n",
    "    # print(OGY_test)\n",
    "\n",
    "    bin_width = 0.1\n",
    "    # Normalized Error Metric (NEM)\n",
    "\n",
    "    dist_sum = 0\n",
    "    for i in range(len(Y_pred)):\n",
    "        dist = abs(Y_pred[i] - OGY_test[i])\n",
    "        dist_sum = dist_sum + dist\n",
    "\n",
    "    print(\"NEM:{}\".format((dist_sum*bin_width)/len(Y_test)))\n",
    "\n",
    "    CP=[]\n",
    "    for i in range(len(Y_pred)):\n",
    "        dist = OGY_test[i] - Y_pred[i]\n",
    "        CP.append(dist)\n",
    "    CP=np.array(CP,dtype=float)\n",
    "\n",
    "    print(\"Confidence Interval:{}\".format(c_int(CP)))\n",
    "\n",
    "    dist_sum = 0\n",
    "    step = 0.1\n",
    "\n",
    "    date=[]\n",
    "    lower_p_bound=[]\n",
    "    higher_p_bound=[]\n",
    "    actual_p=[]\n",
    "        \n",
    "    lower_int_p = []\n",
    "    upper_int_p = []\n",
    "        \n",
    "        \n",
    "################################\n",
    "\n",
    "    for i in range(len(Y_pred)):    \n",
    "        lower_bound_opPrice = ((Y_pred[i]*step) * (feats.loc[i,'strike']))/100\n",
    "        lower_p_bound.append(lower_bound_opPrice)\n",
    "\n",
    "################################\n",
    "\n",
    "    for i in range(len(Y_pred)):    \n",
    "\n",
    "        higher_bound_opPrice = (((Y_pred[i]+1) * step) * (feats.loc[i,'strike']))/100    \n",
    "        higher_p_bound.append(higher_bound_opPrice)\n",
    "\n",
    "\n",
    "################################\n",
    "    for i in range(len(Y_pred)):    \n",
    "\n",
    "        actual_opPrice = feats.loc[i,'opPrice']\n",
    "        actual_p.append(actual_opPrice)                    \n",
    "\n",
    "################################\n",
    "    for i in range(len(Y_pred)):    \n",
    "\n",
    "        lower_lim_opPrice = (((Y_pred[i]-2) * step) * (feats.loc[i,'strike']))/100    \n",
    "        lower_int_p.append(lower_lim_opPrice)    \n",
    "\n",
    "################################\n",
    "    for i in range(len(Y_pred)):    \n",
    "\n",
    "        upper_lim_opPrice = (((Y_pred[i]+3) * step) * (feats.loc[i,'strike']))/100    \n",
    "        upper_int_p.append(upper_lim_opPrice)    \n",
    "    \n",
    "        \n",
    "    priceval_dataSet=pd.DataFrame()\n",
    "    priceval_dataSet['date']=feats['date']\n",
    "    priceval_dataSet['lower_p']=lower_p_bound\n",
    "    priceval_dataSet['higher_p']=higher_p_bound\n",
    "    priceval_dataSet['actual_p']=actual_p\n",
    "    priceval_dataSet['LowerLim_p'] = lower_int_p\n",
    "    priceval_dataSet['UpperLim_p'] = upper_int_p\n",
    "        \n",
    "        \n",
    "        \n",
    "        # print(len(priceval_dataSet))\n",
    "    priceval_dataSet= priceval_dataSet[(priceval_dataSet['lower_p']!=10000)]\n",
    "    priceval_dataSet= priceval_dataSet[(priceval_dataSet['higher_p']!=10000)]\n",
    "    priceval_dataSet= priceval_dataSet[(priceval_dataSet['actual_p']!=10000)]\n",
    "    priceval_dataSet= priceval_dataSet[(priceval_dataSet['LowerLim_p']!=10000)]\n",
    "    priceval_dataSet= priceval_dataSet[(priceval_dataSet['UpperLim_p']!=10000)]\n",
    "        \n",
    "    print(len(priceval_dataSet))\n",
    "#     priceval_dataSet=priceval_dataSet.groupby('date').mean()\n",
    "    decimals = 3    \n",
    "    priceval_dataSet['higher_p'] = priceval_dataSet['higher_p'].apply(lambda x: round(x, decimals))\n",
    "    priceval_dataSet['lower_p'] = priceval_dataSet['lower_p'].apply(lambda x: round(x, decimals))\n",
    "    priceval_dataSet['actual_p'] = priceval_dataSet['actual_p'].apply(lambda x: round(x, decimals))\n",
    "    priceval_dataSet['LowerLim_p'] = priceval_dataSet['LowerLim_p'].apply(lambda x: round(x, decimals))\n",
    "    priceval_dataSet['UpperLim_p'] = priceval_dataSet['UpperLim_p'].apply(lambda x: round(x, decimals))\n",
    "        \n",
    "    print((priceval_dataSet))\n",
    "        \n",
    "    \n",
    "    priceval_dataSet.to_csv(filepath+\"price_vals/Combined_DL_NIFTY_approach_\"+str(approach)+\".csv\", index = False)\n",
    "\n",
    "#     priceval_dataSet['minA']=abs(priceval_dataSet['actual_p']-priceval_dataSet['higher_p'])\n",
    "#     priceval_dataSet['minB']=abs(priceval_dataSet['actual_p']-priceval_dataSet['lower_p'])\n",
    "#     priceval_dataSet['min']=priceval_dataSet[['minA','minB']].min(axis=1)\n",
    "\n",
    "#     print(\"Mean={}\".format(priceval_dataSet['min'].mean()))\n",
    "\n",
    "#     print(\"Median={}\".format(priceval_dataSet['min'].median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>lower_p</th>\n",
       "      <th>higher_p</th>\n",
       "      <th>actual_p</th>\n",
       "      <th>LowerLim_p</th>\n",
       "      <th>UpperLim_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>232.8</td>\n",
       "      <td>242.50</td>\n",
       "      <td>221.2</td>\n",
       "      <td>213.4</td>\n",
       "      <td>261.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>118.2</td>\n",
       "      <td>128.05</td>\n",
       "      <td>120.3</td>\n",
       "      <td>98.5</td>\n",
       "      <td>147.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>10.2</td>\n",
       "      <td>20.40</td>\n",
       "      <td>12.2</td>\n",
       "      <td>-10.2</td>\n",
       "      <td>40.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>20.3</td>\n",
       "      <td>30.45</td>\n",
       "      <td>17.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>20.2</td>\n",
       "      <td>30.30</td>\n",
       "      <td>24.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2674</th>\n",
       "      <td>2018-09-26</td>\n",
       "      <td>168.0</td>\n",
       "      <td>179.20</td>\n",
       "      <td>149.3</td>\n",
       "      <td>145.6</td>\n",
       "      <td>201.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2675</th>\n",
       "      <td>2018-09-26</td>\n",
       "      <td>91.2</td>\n",
       "      <td>102.60</td>\n",
       "      <td>70.8</td>\n",
       "      <td>68.4</td>\n",
       "      <td>125.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2676</th>\n",
       "      <td>2018-09-26</td>\n",
       "      <td>90.8</td>\n",
       "      <td>102.15</td>\n",
       "      <td>87.9</td>\n",
       "      <td>68.1</td>\n",
       "      <td>124.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2677</th>\n",
       "      <td>2018-09-26</td>\n",
       "      <td>222.0</td>\n",
       "      <td>233.10</td>\n",
       "      <td>203.9</td>\n",
       "      <td>199.8</td>\n",
       "      <td>255.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2678</th>\n",
       "      <td>2018-09-26</td>\n",
       "      <td>275.0</td>\n",
       "      <td>286.00</td>\n",
       "      <td>265.8</td>\n",
       "      <td>253.0</td>\n",
       "      <td>308.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2679 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  lower_p  higher_p  actual_p  LowerLim_p  UpperLim_p\n",
       "0    2017-10-03    232.8    242.50     221.2       213.4      261.90\n",
       "1    2017-10-03    118.2    128.05     120.3        98.5      147.75\n",
       "2    2017-10-03     10.2     20.40      12.2       -10.2       40.80\n",
       "3    2017-10-03     20.3     30.45      17.6         0.0       50.75\n",
       "4    2017-10-03     20.2     30.30      24.7         0.0       50.50\n",
       "...         ...      ...       ...       ...         ...         ...\n",
       "2674 2018-09-26    168.0    179.20     149.3       145.6      201.60\n",
       "2675 2018-09-26     91.2    102.60      70.8        68.4      125.40\n",
       "2676 2018-09-26     90.8    102.15      87.9        68.1      124.85\n",
       "2677 2018-09-26    222.0    233.10     203.9       199.8      255.30\n",
       "2678 2018-09-26    275.0    286.00     265.8       253.0      308.00\n",
       "\n",
       "[2679 rows x 6 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priceval_dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = priceval_dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
