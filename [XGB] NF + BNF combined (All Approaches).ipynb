{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all libraries\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler, RobustScaler\n",
    "import matplotlib as plt\n",
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics as stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path settings\n",
    "\n",
    "\n",
    "path_var = 1 \n",
    "\n",
    "if (path_var == 1):\n",
    "    filepath = '/home/docboy/Desktop/Option_Pricing/datasets/'\n",
    "    modelpath = '/home/docboy/Desktop/Option_Pricing/pickles/'\n",
    "\n",
    "\n",
    "else:\n",
    "    filepath = '/home/sharan/Desktop/Option_Pricing/datasets/'\n",
    "    mdoelpath = '/home/sharan/Desktop/Option_Pricing/pickles/'\n",
    "\n",
    "\n",
    "\n",
    "nfty = filepath + 'NIFTY50_feature_set_COV_complete.csv'\n",
    "nfty_ecdf = filepath + 'NIFTY50_feature_set_ECDF_complete.csv'\n",
    "    \n",
    "bnfty = filepath + 'BANKNIFTY_feature_set_COV_complete.csv'\n",
    "bnfty_ecdf = filepath + 'BANKNIFTY_feature_set_ECDF_complete.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approach var set to :: 3\n"
     ]
    }
   ],
   "source": [
    "# Set the automated variables + Plus drop all useless columns approach specific\n",
    "\n",
    "\n",
    "###########################\n",
    "###############################################\n",
    "\n",
    "approach = 3                     #------------------>>> # Change value as needed\n",
    "\n",
    "###############################################\n",
    "###########################\n",
    "\n",
    "\n",
    "if (approach == 1):\n",
    "    n_feats = pd.read_csv(nfty_ecdf)\n",
    "    print ('Approach var set to ECDF')\n",
    "    \n",
    "    dropNames = ['date', 'percentage','strike','spot','opPrice']\n",
    "    \n",
    "    b_feats = pd.read_csv(bnfty_ecdf)\n",
    "    \n",
    "else:\n",
    "    n_feats = pd.read_csv(nfty)\n",
    "    print ('Approach var set to :: '+ str(approach))\n",
    "    \n",
    "    b_feats = pd.read_csv(bnfty)\n",
    "    \n",
    "    if (approach == 2):\n",
    "        dropNames= ['date', 'percentage','strike','spot','opPrice','change_oi','ts_atr','prevOp','avg_atmError']\n",
    "        \n",
    "    else:\n",
    "        dropNames= ['date', 'percentage','strike','spot','opPrice','ts_atr','change_oi']\n",
    "        \n",
    "###################\n",
    "\n",
    "n_feats = n_feats.drop(dropNames, axis = 1)\n",
    "b_feats = b_feats.drop(dropNames, axis = 1)\n",
    "\n",
    "feats = n_feats.append(b_feats, ignore_index=True)\n",
    "\n",
    "X=feats.iloc[:,:-1]\n",
    "Y=feats.loc[:,'Target']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "featNames = list(X)  \n",
    "scaler = RobustScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(X, columns = featNames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler saved to path :: /home/docboy/Desktop/Option_Pricing/pickles/SCALER_NF+BNF_Expt3.model\n"
     ]
    }
   ],
   "source": [
    "# # Save the scalar file\n",
    "\n",
    "joblib.dump(scaler, modelpath + 'SCALER_NF+BNF_Expt' + str(approach) + '.model')\n",
    "print(\"Scaler saved to path ::\", modelpath + 'SCALER_NF+BNF_Expt' + str(approach) + '.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X & Y_Dim of Train is (27144, 19) (27144, 1)\n",
      "X & Y_Dim of Test is (6786, 19) (6786, 1)\n"
     ]
    }
   ],
   "source": [
    "# Split the train and test sets without random optimizations\n",
    "\n",
    "\n",
    "a = len(n_feats)\n",
    "split_val = round(a*0.8)\n",
    "\n",
    "# Removing the Random splits\n",
    "\n",
    "Ntrain = n_feats.iloc[0:split_val, :]\n",
    "Ntest = n_feats.iloc[split_val:, :]\n",
    "\n",
    "b = len(b_feats)\n",
    "split_val = round(b*0.8)\n",
    "\n",
    "# Removing the Random splits\n",
    "\n",
    "Btrain = b_feats.iloc[0:split_val, :]\n",
    "Btest = b_feats.iloc[split_val:, :]\n",
    "\n",
    "\n",
    "train = Ntrain.append(Btrain, ignore_index=True)\n",
    "\n",
    "train = train.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "test = Ntest.append(Btest, ignore_index=True)\n",
    "\n",
    "test = test.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "X_train=train.iloc[:,:-1]\n",
    "X_train = scaler.transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns = featNames)\n",
    "Y_train=train.loc[:,'Target']\n",
    "Y_train = Y_train.values\n",
    "Y_train = Y_train.reshape(len(Y_train), 1)\n",
    "\n",
    "X_test=test.iloc[:,:-1]\n",
    "X_test = scaler.transform(X_test)\n",
    "X_test = pd.DataFrame(X_test, columns = featNames)\n",
    "Y_test=test.loc[:,'Target']\n",
    "Y_test = Y_test.values\n",
    "Y_test = Y_test.reshape(len(Y_test), 1)\n",
    "\n",
    "print ('X & Y_Dim of Train is', X_train.shape, Y_train.shape)\n",
    "print ('X & Y_Dim of Test is', X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/docboy/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/docboy/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# param = \n",
    "model = XGBClassifier(n_estimators = 250, max_depth = 4, learning_rate = 0.25, n_jobs=4)\n",
    "%time model.fit(X_train, Y_train)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized Error Metric (NEM)\n",
    "\n",
    "bin_width = 0.1    # Note the uniform binning!!!!!!!!\n",
    "dist_sum = 0\n",
    "for i in range(len(k)):\n",
    "    dist = abs(k[i] - Y_test[i])\n",
    "    dist_sum = dist_sum + dist\n",
    "    \n",
    "print(\"NEM :: \", (dist_sum*bin_width)/len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(Y_test, k)*100\n",
    "# print(classification_report(Y_test, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "joblib.dump(model, modelpath + 'NF+BNF_Expt' + str(approach) + '.model')\n",
    "print(\"Model saved to path ::\", modelpath + 'NF+BNF_Expt_NEW' + str(approach) + '.model' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [20, 25]\n",
    "plot_importance(model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing BNF+NF on NF and BNF separately "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NF\n",
    "\n",
    "\n",
    "n_feats = n_feats.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "nf_Ytest = n_feats.loc[:, 'Target']\n",
    "nf_Xtest = n_feats.iloc[:, :-1]\n",
    "\n",
    "featNames = list(nf_Xtest)\n",
    "\n",
    "nf_Xtest = scaler.transform(nf_Xtest)\n",
    "nf_Xtest = pd.DataFrame(nf_Xtest, columns = featNames)\n",
    "\n",
    "\n",
    "pred = model.predict(nf_Xtest)\n",
    "\n",
    "dist_sum = 0\n",
    "for i in range(len(pred)):\n",
    "    dist = abs(pred[i] - nf_Ytest[i])\n",
    "    dist_sum = dist_sum + dist\n",
    "    \n",
    "print(\"NEM ::\", (dist_sum*bin_width)/len(nf_Ytest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BNF\n",
    "\n",
    "\n",
    "bnf_Ytest = b_feats.loc[:, 'Target']\n",
    "bnf_Xtest = b_feats.iloc[:, :-1]\n",
    "\n",
    "featNames = list(bnf_Xtest)\n",
    "\n",
    "bnf_Xtest = scaler.transform(bnf_Xtest)\n",
    "bnf_Xtest = pd.DataFrame(bnf_Xtest, columns = featNames)\n",
    "\n",
    "\n",
    "pred = model.predict(bnf_Xtest)\n",
    "\n",
    "dist_sum = 0\n",
    "for i in range(len(pred)):\n",
    "    dist = abs(pred[i] - bnf_Ytest[i])\n",
    "    dist_sum = dist_sum + dist\n",
    "    \n",
    "print(\"NEM ::\", (dist_sum*bin_width)/len(bnf_Ytest))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
